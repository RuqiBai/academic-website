---
title: Exploring Adversarial Examples via Invertible Neural Networks
publication_types:
  - "3"
authors: []
abstract: >
  Adversarial examples (AEs) are images that can mislead deep neural network
  (DNN) classifiers via introducing slight perturbations into original images.
  This security vulnerability has led to vast research in recent years because
  it can introduce real-world threats into systems that rely on neural networks.
  Yet, a deep understanding of the characteristics of adversarial examples has
  remained elusive. We propose a new way of achieving such understanding through
  a recent development, namely, invertible neural models with Lipschitz
  continuous mapping functions from the input to the output. With the ability to
  invert any latent representation back to its corresponding input image, we can
  investigate adversarial examples at a deeper level and disentangle the
  adversarial example's latent representation. Given this new perspective, we
  propose a fast latent space adversarial example generation method that could
  accelerate adversarial training. Moreover, this new perspective could
  contribute to new ways of adversarial example detection.

  Subjects:	Machine Learning (cs.LG); Cryptography and Security (cs.CR)

  Cite as:	arXiv:2012.13111 [cs.LG]
   	(or arXiv:2012.13111v1 [cs.LG] for this version)
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2021-02-03T17:18:59.197Z
---
